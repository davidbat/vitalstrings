0.81
1.0
The Miskolczi estimate is based on a  greenhouse theory with energy constraints that fully determines the strength of  the greenhouse effect. It predicts the increasing CO2 concentrations would  reduce the quantity of water vapour in the upper troposphere. In fact, the water  vapour relative humidity has declined 21% from 1950 to 2007 at 9 km  altitude.
The Idso and Spencer estimates are based on  temperature change observations, but do not take account of the effect of  reduced water vapour in response to increasing CO2, and so are likely too high.  (The Spencer article presents a climate sensitivity estimate of 8 W/m2/C, which  is the reciprocal of the 0.125 C/W/m2 shown in the above  table.)
The Schwartz and Chylek estimates both  assume that the Sun has no effect on the temperature increase, and attributes  the 20th century temperature change to CO2, modified by aerosols. This  assumption greatly over-estimates the climate sensitivity due to CO2. The  estimates also rely on the surface temperature record, which is contaminated by  the urban heat island effect. 
The IPCC determined climate  sensitivity by two methods:
comparing short term temperature variation with the    radiation emission from the top of the atmosphere from satellite data,    and
by interpreting indirect clues from the    geological record
Climate  sensitivity estimates used by the IPCC assumed that observed  temperature variability caused the observed cloud variability.  But causation also flows in the opposite direction with cloud variability  causing temperature variability. A temperature change caused by cloud  variability would be incorrectly interpreted as a positive feedback. This  error causes the estimates to have a built-in bias toward high climate  sensitivity. We know that the Sun can cause a change in lower cloud cover which  cause a temperature change. The IPCC does not consider possible climate change  from the Sun as its mandate is to investigate man-made climate change. The analysis of indirect clues from the geological record is  very uncertain. The IPCC 4AR give a range of climate sensitivity of 2 to 4.5  C/W/m2, with a best estimate of 3 C/W/m2.
The following  chart from a presentation by Dr. Richard Lindzen shows prediction results from a  number of climate models and satellite data. The horizontal axis shows the  change in sea surface temperatures per year as measured over various time  intervals. The vertical axis is the change in outgoing longwave radiation at the  top of the atmosphere as predicted by several climate  models.
A positive  correlation (slope from bottom left to top right) indicates that there is a  negative feedback loop in SST change such that the hotter the sea gets the more  heat is radiated away to space, which reduces the temperature rise. A negative  correlation (slope from top left to bottom right) indicates that there is a  positive feedback loop in that the atmosphere inhibits heat loss to space, which  increases the temperature further.
 
The first  correlation labeled ERBE is the actual data as measured by the Earth  Radiation Budget Experiment (ERBE) satellite. The slope of the line indicates a  strong negative feedback which offsets the initial temperature rise. The eleven  other correlations are from climate models. They all show negative correlations  corresponding to positive feedbacks, which amplifies the initial temperature  rise. All the models have the feedback in the wrong direction, confirming that  the models are fundamentally wrong.
In the following  graph, each climate model's predicted climate sensitivity is plotted versus  the slope of the correlations shown above, which correspond to the amount of the  temperature feedback.  The curved black line shows the relation between the  feedback and the climate sensitivity to doubling the amount of carbon dioxide in  the atmosphere. The large errors in the feedback factors cause a large range of  predicted equilibrium climate sensitivities. The model results show the climate  sensitivity could range from 1.3 degrees to over 5 degrees Celsius considering  the range of feedback factors. But the ERBE satellite data tells a completely  different story. It shows a climate sensitivity of 0.4 to 0.5 degrees Celsius.  This small temperature change would not cause any problem and it there is no  reason to be concerned about our CO2 emissions.  See here or here for further information.
The ERBE determined climate  sensitivity may be too high because it was calculated from short term  temperature variations. It does not account for the long term reduction in water  vapour content in the atmosphere as shown in the  Water Vapour Feedback  section, so the long term  climate sensitivity may be even less than that indicated here. 
The IPCC Hockey  Stick
The IPCC published the "Hockey Stick" graph from Mann,  Bradley and Hughes (MBH 1998), in its Third Assessment Report, which shows  little change in temperatures for hundreds of years then a sharp increase  recently in the last hundred years. This temperature history was given bold  prominence in the IPCC reports, distributed to all Canadian households and used  to support major policy decisions involving the expenditure of billions of  dollars. The IPCC argues that there was little natural climate change over the  last 1000 years, so that the temperature change over the last 100 years is  unusual and likely caused by human activities. A senior IPCC researcher said in  an email "We have to get rid of the Medieval Warm Period." Christopher Monckton  says "They did this by giving one technique, measurement of tree-rings from  bristlecone pines, 390 times more weighting than other techniques but didn't  disclose this. Tree-rings are wider in warmer years, but pine tree rings are  also wider when there's more carbon dioxide in the air: it's plant food. This  carbon dioxide fertilization distorts the calculations. They said they had  included 24 data sets going back to 1400. Without saying so, they left out the  set showing the medieval warm period, tucking it into a folder marked "Censored  Data". They used a computer model to draw the graph from the data, but two  Canadians [Ross McKitrick and Stephen McIntyre] later found that the model  almost always drew hockey-sticks even if they fed in random, electronic "red  noise" because it used a faulty algorithm."  The MBH 1998 report was never  properly peer reviewed before the IPCC used it in their publications. 
See here for comments from  Christopher Monckton .
McKitrick and McIntyre say in their paper "the  dataset used to make this construction contained collation errors, unjustified  truncation or extrapolation of source data, obsolete data, incorrect principal  component calculations, geographical mislocations and other serious defects.  These errors and defects substantially affect the temperature index. The major  finding is that the values in the early 15th century exceed any values in the  20th century. The particular “hockey stick” shape derived in the MBH98 proxy  construction – a temperature index that decreases slightly between the early  15th century and early 20th century and then increases dramatically up to 1980 —  is primarily an artefact of poor data handling, obsolete data and incorrect  calculation of principal components."  See here for  their paper .
The IPCC hockey stick is shown below, along with the  corrected version. The error ranges are not shown here.
The dispute over the hockey stick caused the  United States Congress to decide to investigate the matter. The US National  Research Council (NRC) held public hearings and prepared a report in 2006 for  the US House of Representatives Committee on Science.  The NRC Report made  no criticism of the McKitrick and McIntyre papers. The report concludes  "strip-bark samples should be avoided in temperature reconstructions." These  strip-bark Bristlecone/Foxtail samples are responsible for the sharp increase in  the graph in the twentieth century, but the growth spurt is not related to  temperatures. It also confirmed that Mann's algorithm, which used non-centered  principal component analysis, mines for hockey stick shapes from random red  noise data as previously shown by McKitrick and McIntyre, and notes that  "uncertainties of the published reconstructions have been underestimated."
Meanwhile, the US House of Representatives Committee on Energy and  Commerce had independently commissioned a study from Edward Wegman who is  chairman of the NAS Committee on Applied and Theoretical Statistics and a Fellow  of the Royal Statistical Society. The Wegman Report states "Overall, our  committee believes that Mann’s assessments that the decade of the 1990s was the  hottest decade of the millennium and that 1998 was the hottest year of the  millennium cannot be supported by his analysis.” It also states "In general, we  find the criticisms by [the McKitrick and McIntyre papers] to be valid and their  arguments to be compelling. We were able to reproduce their results and offer  both theoretical explanations (Appendix A) and simulations to verify that their  observations were correct.” The study also studied the social network of the  group of scientists who publish temperature reconstructions. The study found  that they collaborate with each other and share proxy data and methodologies, so  that the "independent" studies are not independent at all. See the Wegman Report here .
Both  of these reports were public six months before the IPCC began the release of the  Fourth Assessment Report; however, the 4AR makes no mention of the Wegman  Report, gives only one citation of the NRC Report, and ignores the findings and  recommendations of the reports.
David Holland wrote a comprehensive  history and discussion of the hockey stick affair.  See Holland's paper -  "Bias and Concealment in the IPCC Process: The 'Hockey Stick' Affair and its  Implications" published by "Energy & Environment", October 2007 here .
David  Holland says "it is scandalous that the WGI Chapter 6 authors ignored most of  its [NRC Report]  substantive findings.  Despite the clear analysis in  Wegman et al. showing the lack of independence between the various temperature  reconstructions, the authors of AR4 WGI Chapter 6 persisted with their reliance  on a “spaghetti” diagram of reconstructions in Figure 6.10(b) to continue to  justify the claim that “Average Northern Hemisphere temperatures during the  second half of the 20th century were likely the highest in at least the past  1,300 years.”
 
Urban Heat  Island Effects
The urban heat island effect is caused by  the heat-retaining properties of concrete and asphalt in urban areas that  artificially increase local temperatures. It is the effect that humans have on  local surface temperature so that the temperatures in or near urban centres are  warmer than rural areas.
                        Surface  Temperature Trends in 47 California Counties
This graph shows the size of the effect on surface temperatures  and the problems associated with objective sampling. The surface temperature  trends determined from ground stations for the period 1940 to 1996 were averaged  for each county. The trends were grouped by county population and plotted as  closed circles along with the standard errors of their means. The straight line  is a least-squares fit to the closed circles. The points marked ''X'' are the  six unadjusted station records selected by NASA GISS for use in their estimate  of global temperatures. Note that 5 of the 6 selected stations are in populous  counties. Note also that extrapolating the straight line to a county population  of 10,000 gives a temperature trend of zero. See here .
Here  is an example of a weather station used by  the IPCC to record temperature rise.
                            Temperature Trends of Major City  Sites and Rural Sites
Peterson  (2003)   is an influential study cited by IPCC Fourth Assessment Report  purporting to show that the urbanization effect is negligible.
The  IPCC  relied heavily on this flawed study, where Peterson states "no  statistically significant impact of urbanization could be found in annual  temperatures." However, Steve McIntyre using Peterson's data shows that "actual  cities have a very substantial trend of over 2 deg C per century relative to the  rural network - and this assumes that there are no problems with rural network -  something that is obviously not true since there are undoubtedly microsite and  other problems." Peterson uses two lists of stations in his study, one labelled  Urban and one labelled Rural. However an analysis of the lists shows that the  Urban list includes many rural sites and the Rural list includes many urban  sites. These results are discussed in a Climate Audit article here .
Most scientist agree  that many temperature station measurements are contaminated by urban heat island  effects, but they argue that the major global temperature indexes are adjusted  to correct for these effects. There is an "Urbanization Adjustment" to correct  for the effects of urbanization, a "Time of Observation Bias Adjustment" to  correct for changed to the time of day when measurements are taken, and there is  a "Coverage Adjustment" to account for the loss of measurement stations. These  adjustments are intended to produce a record of what the temperatures would be  if nobody lived near the measurement stations. If the adjustments were adequate,  there should be no statistically significant correlation between the temperature  record and social economic indicators.
Ross McKitrick and Patrick  Michaels published a paper in 2004 in which they analyse the pattern of warming  over the Earth's land surface compared to local economic conditions. They found  a statistically significant correlation between the adjusted temperature data  and economic development, meaning that the adjustments are not adequate to  remove the urban heat island effects. They conclude "If the contamination were  removed, we estimated the average measured warming rate over land would decline  by about half."
Dutch meteorologists, Jos de Laat and Ahilleas Maurellis  using different testing methodologies came to similar conclusions. They showed  that there is a statistically significant correlation between the spacial  pattern of warming in the adjusted temperature data and the spacial pattern of  industrial development. They concluded it adds a large upward bias to the  measured global warming trend. They also show that climate model predictions  show no correlation between temperature and industrial development.
The  IPCC acknowledges the correlation between the warming trends and social economic  development, but dismisses it as a mere coincidence, due to unspecified  “atmospheric circulation changes.” This nonsense claim contradict the IPCC  widley advertised claim that recent warming can not be attributed to natural  causes, and the Laat and Maurellis research shows it to be  false.
McKitrick and Michaels published an updated paper in December 2007  using a larger data set with a more complete set of socioeconomic indicators.  They discussed two types of contamination; anthropogenic surface processes,  which are changes to the landscaped due to urbanization or agriculture, and  inhomogeneities, i.e. equipment changes, missing data, poor quality control,  etc. They showed that the spatial pattern of warming trends is tightly  correlated with indicators of economic activity.  They present a battery of  statistical tests to prove that the result is not a fluke or spurious  correlation. They conclude "The average trend at the surface in the post-1980  interval would fall from about 0.30 degrees (C) per decade to about 0.17  degrees." Removing the net warming bias due to urban heat effects in surface  temperature data could explain as much as half the recent warming over  land.
                                      
Bias of IPCC Temperature Data
The graph above is from the McKitrick and Michaels  December 2007 paper. Each square is colour-coded to indicate the size of the  local bias. Blank areas indicate that there was no data available. See the  Background Discussion on the paper here .
An audit by researcher Steve McIntyre reveals that NASA has made  urban adjustments of temperature data in its GISS temperature record in the  wrong direction. NASA has applied a "negative urban  adjustment" to 45% of the urban station measurements (where adjustments are  made), meaning that the adjustments make the warming trends steeper. The urban adjustment is supposed to remove the effects of  urbanization, but the NASA negative adjustments increases the urbanization  effects. The result is that the surface temperature trend utilized by the  International Panel on Climate Change (IPCC) is exaggerated. See here .
The website www.surfacestations.org was created by  Anthony Watts in response to the realization that very little physical site  survey data exists for the entire United States Historical Climatological  Network (USHCN) of surface stations. Volunteers do hands on site  surveys to photograph and document all 1221 USHCN climate stations in the USA.  As of February 2009, 854 of 1221 stations have been examined in the USHCN  network. Each site is assigned a site quality rating 1 through 5 based on the  Climate Reference Network Rating Guide. Only 11% of stations are in suitable  locations, 69% are within 10 m of an artificial heat source. Below is a picture  of a poorly situated station.
 
The graph "Surface and Troposphere Temperature Trends"  presented in the Heating of the Troposphere section of this essay shows  temperature trends of the land, of the land and sea, and of the troposphere in  the tropics. The land surface temperature trend has the highest rate of increase  because it is contaminated by the heat island effect. The land and sea surface  temperature trend is lower than the land trend because the sea temperature data  does not have any heat island effect. The troposphere shows the lowest rate of  temperature increase. We know that the CO2 theory of climate change requires the  troposphere to warm faster than the surface, but the opposite has happened. It  is illogical to believe that CO2 is the primary temperature driver and  concurrently believe that the surface measurements used to the IPCC are  accurate. If the surface temperature data were fully adjusted to remove the  effects of urbanization by reducing the warming rate by half, it would closely  match the troposphere warming trend.
Falsified Historical CO2  Measurements
The  IPCC uses a CO2 concentration history that shows a low pre-industrial CO2  content which increases during the industrial era. The IPCC may have used  corrupted CO2 data in its analysis of climate change. Their conclusions and  projections of climate change are all based on the assumption of low CO2  concentrations in the pre-industrial atmosphere based on ice core studies.  Unfortunately, ice cores do not form a closed system. In the highly compressed  deep ice, CO2 combines with liquid water to form gas hydrates, or clathrates,  which are tiny crystals. When the ice core is brought to the surface, the  pressure falls causing the clathrates to decompose to the gas form, exploding in  the process as if they were microscopic grenades, forming tiny cracks in the  ice. Other cracks are formed by the ice decompression. Gas escapes through these  cracks as the ice core is brought to the surface, but since CO2 forms clathrates  at lower pressures than other gases, CO2 is preferentially lost leading to  depletion of CO2 in the gas trapped in the ice core. Consequently, the measured  CO2 concentration from deep ice cores is less than the CO2 concentration of the  originally trapped air.
The graph on the left shows the  IPCC history of CO2 concentration in air.
Data from  shallow ice cores such as from Siple, Antarctica, show that the CO2  concentration of pre-industrial ice (from depths too shallow for clathrate  formation) are much higher than that measured at Mauna Loa, Hawaii in  1960. 
 Actual Siple, Antarctica Ice Core and Mauna Loa Data
Note that the measured  concentration declines with increasing load pressure and  depth.
Shifted Siple, Antarctica Ice Core and Mauna  Loa Data
 As the  actual measurements show ice deposited in 1890 AD is 328 ppm, not the 290 ppm  required to fit the IPCC human caused increasing CO2 concentration and global  warming hypothesis, the average age of air was arbitrarily decreed to be exactly  83 years younger than the ice in which it was trapped.
The “corrected”  ice data were then smoothly aligned with the Mauna Loa record, and reproduced in  countless publications as a famous “Siple curve”. Only thirteen years later, in  1993, glaciologists attempted to prove experimentally the “age assumption”, but  they failed.
        CO2  Measurements between 1800 and 1955
IPCC modellers ignored the direct  measurements of CO2 concentration indicating that the 19th century CO2  concentration was 335 ppm.
The encircled values were arbitrarily selected  by Callendar for estimation of 292 ppm as the average 19th century CO2  concentration.
A study of stomatal frequency in fossil leaves  from Holocene lake deposits in Denmark, showing that 9400 years ago CO2  atmospheric level was 333 ppm, and 9600 years ago 348 ppm, falsify the concept  of stabilized and low CO2 air concentration until the advent of industrial  revolution.
See here for more  information .
Recently, Ernst-Georg Beck has summarized 90,000  accurate chemical analysis of CO2 in air since 1812. The historic chemical data  reveal that changes in CO2 track changes in temperature, and therefore climate  in contrast to the simple, monotonically increasing CO2 trend depicted in the  post 1990 literature on climate change. Since 1812, the CO2 concentration in  northern hemispheric air has fluctuated exhibiting three high level maxima  around 1825, 1857 and 1942 the latter showing more than 400 ppm.
Between 1857 and 1958, the  Pettenkofer process was the standard analytical method for determining  atmospheric carbon dioxide levels, and usually achieved accuracy better than 3%.  These determinations were made by several scientists of Nobel Prize level  distinction. Following Callendar (1938), modern climatologists have generally  ignored the historic determinations of CO2, despite the techniques being  standard textbook procedures in several different disciplines. Chemical methods  were discredited as unreliable choosing only few which fit the assumption of a  climate CO2 connection.
Ernst-Georg Beck calls the falsification of the  CO2 record "The greatest scandal in the modern history of science".
See here for a  summary of the Beck paper, or here for the paper
See here for Beck's Berlin presentation of May 30, 2007.
See here for CO2: The Greatest Scientific Scandal of Our Time, by Zbigniew Jaworowski,  Spring/Summer 2007 21st CENTURY Science & Technology.
No  Consensus
Author Michael Crichton warned of the dangers of  "consensus science" in a 2003 speech. He says "Consensus is the business of  politics. Science, on the contrary, requires only one investigator who happens  to be right, which means that he or she has results that are verifiable by  reference to the real world. In science consensus is irrelevant. What is  relevant is reproducible results. The greatest scientists in history are great  precisely because they broke with the consensus."
In an open letter to  Prime Minister Stephen Harper, 61 prominent scientists called for an open  climate science review. The letter states "Observational evidence does not  support today's computer climate models, so there is little reason to trust  model predictions of the future. Significant advances have been made since the  protocol was created, many of which are taking us away from a concern about  increasing greenhouse gases. If, back in the mid-1990s, we knew what we know  today about climate, Kyoto would almost certainly not exist, because we would  have concluded it was not necessary. Global climate changes all the time due to  natural causes and the human impact still remains impossible to distinguish from  this natural "noise.""
The Petition Project was organized by the Oregon  Institute of Science and Medicine.
The petition states in  part:
 "There is no convincing scientific evidence that human release of  carbon dioxide, methane, or other greenhouse gasses is causing or will, in the  foreseeable future, cause catastrophic heating of the Earth's atmosphere and  disruption of the Earth's climate. Moreover, there is substantial scientific  evidence that increases in atmospheric carbon dioxide produce many beneficial  effects upon the natural plant and animal environments of the Earth."
So  far (May 2009) the petition has received 31,478 signatures. Signatories are  approved for inclusion in the Petition Project list if they have obtained formal  educational degrees at the level of Bachelor of Science or higher in appropriate  scientific fields. All of the listed signers have formal educations in  fields of specialization that suitably qualify them to evaluate the research  data related to the petition statement. Many of the signers currently work in  climatological, meteorological, atmospheric, environmental, geophysical,  astronomical, and biological fields directly involved in the climate change  controversy.  See here .
The Heartland  Institute has conducted an international survey of 530 climate scientists in  2003. The survey asked if “the current state of scientific knowledge is  developed well enough to allow for a reasonable assessment of the effects of  greenhouse gases.” Two-thirds of the scientists surveyed (65.9 percent)  disagreed with the statement, with nearly half (45.7 percent) scoring it with a  1 or 2, indicating strong disagreement. Only 10.9 percent scored it with a 6 or  7, indicating strong agreement. See here for the full survey  results .
In an Open Letter to the Secretary-General of the United  Nations, and the head of states of many nations dated December 13, 2007, titled  "UN Climate Conference Taking the World in Entirely the Wrong Direction", more  than 100 specialists from around the world, many who are leading scientists,  state that "It is not possible to stop climate change, a natural phenomenon that  has affected humanity through the ages." The letter states than recent climate  changes have been well with-in the bounds of known natural variability. It  further states that climate models can not predict climate, that there has been  no global warming since 1998, that the IPCC has ignored much significant new  peer-reviewed research that has cast even more doubt on the hypothesis of  dangerous human-caused global warming, and attempts to cut emissions will slow  development, and is likely to increase human suffering from future climate  change rather than to decrease it.  See here for the letter as published by the National Post.
A report to the US  Senate lists 400 qualified scientists from around the world who dispute the  claims by IPCC and others, that "climate science is settled" and that there is a  "consensus". See here .
There  is no consensus on whether or to what degree human activities are causing “the  problem”, or even whether there is a problem. Global cooling, widely predicted  in the 1970s, would have been much more dangerous than warming.
Effects of  Warming
The IPCC and related groups have suggested several  adverse effects of global warming. Real world data shows that these claims are  mostly false. They ignore the huge benefits of warming and of CO2 emissions on  plant growth.
 
    Global Sea  Level Rise
There has been no change in the rate of sea level  rise in the last 100 years as shown below.
                   Sea Level  Data
 
 
Mean global sea level (gsl) (top), with its shaded 95% confidence  interval, and mean gsl rate (bottom), with its shaded standard error interval.  Adapted from Jevrejeva et al. (2006). See here from  CO2science .
The IPCC AR4 estimates that "Global average sea level  rose at an average rate of 1.8 [1.3 to 2.3] mm per year over 1961 to 2003. The  rate was faster over 1993 to 2003, about 3.1 [2.4 to 3.8] mm per year." It also  states "There is high confidence that the rate of observed sea level rise  increased from the 19th to the 20th century."
Since August 1992 the satellite altimeters have been measuring sea level on a  global basis. The University of Colorado at Boulder provides data from a series  of satellites. Tide gauge calibrations are used to estimate altimeter drift. The  global sea level rise with the seasonal signal removed is shown here . It  shows a trend from 1992 thru March 2009 of 3.1 mm/year. Below are graphs of  global, Pacific ocean and Atlantic ocean sea levels, with trends from  January 2004 to March 2009, seasonal signals included.
Note that there has been a significant flattening of the trend since 2004.  The global sea level rise since January 2004 of 1.52 mm/year is less than  half of the overall trend from 1992 of 3.1 mm/year. The trends since January  2004 of the Pacific and Atlantic oceans are 0.15 mm/year and 0.37 mm/year,  respectively. The slowing of the sea level rise is consistent with the current  lack of global warming.
Dr. Nils-Axel Morner, who has spent a lifetime in the study of sea levels,  says “There is a total absence of any recent ‘acceleration in sea level rise’ as  often claimed by IPCC and related groups.”. Read his fascinating interview " Claim That Sea Level  Is Rising Is a Total Fraud " June 22, 2007 EIR Economics 33.
Dr.  Morner says the global sea level has been rising at 1.1 mm/year from 1850 to  about 1940, then no increase to 1970. The IPCC uses a tide gauge in Hong Kong  that shows 2.3 mm/year of sea level rise. The tide gauge is located where the  land is known to be subsiding, so the record should not be used. Satellite  altimetry data from the TOPEX/POSEIDON mission measures the sea level relative  to the centre of the Earth (rather than relative to the coast) since 1992.
                        Satellite altimetry of  TOPEX/POSEIDON
The graph above  from Morner, 2004, shows the original satellite sea level data from 1992 to  early 2000. Other than the effect of the 1997/98 El Nino, the data shows no sea  level rise.
The satellite data shows no increase, but the IPCC adds a  "correction factor" to the satellite data to make it agree with the tide gauge  data at 2.3 mm/year. This data is presented as satellite data, but Morner says  "it is a falsification of the data set".
                   Satellite Altimetry Data  of TOPEX/POSEIDON Tilted Back to Original Level
The graph above from Morner, 2005, shows the satellite  altimetry sea level data from 1993 to 2003 tilted back to the original level by  excluding the tide-gauge factor. It shows variability around zero plus ENSO  events.
See here  for Dr. Morner's Memoradum paper , which was presented to the United  Kingdom's House of Lords.
Satellite altimetry Topex/Poseidon data is  adjusted by the University of Colorado for NASA to match the rate of sea level  rise measured by a set of 64 tide gauges. Any difference between the raw  satellite measurement and the tide gauge measurement is assumed to be the sum of  satellite measurement drift error and the vertical land movement at the tide  gauge location. A separate estimate of the land movement is made mainly by using  "doppler orbitography and radiopositioning integrated by satellite" (DORIS) data  at the tide gauge location. The raw satellite data is tilted by applying the  satellite measurement drift as determined by the tide gauges. See here   and here for a description of how satellite data is calibrated from a set of tide  gauges.
The graph above shows the sea level trends from January 2002 to April 2011.  Note that most of the sea level rise in this period is located in an area north  of Australia. The average of five tide gauge stations' trends from the  north coast of Australia using annual data is 17.7 mm/year from 2002 to  2009. However, the tropical Pacific ocean sea level was decreasing at up to 16  mm/year.
A famous tree in the Maldives shows no evidence of having been  swept away by rising sea levels, as would be predicted by the global warming  advocates. A group of Australian global-warming advocates came along and pulled  the tree down, destroying the evidence that their “theory” was false.
The  "INQUA Commission on Sea-Level Change and Coastal Evolution" led by Dr. Morner,  prepared as estimate that the global sea level will rise 10 cm plus or minus 10  cm in the next 100 years. Dr. Morner has since revised his estimate to 5 cm per  100 years after considering data of the Sun activity suggesting that the warming  trend may have ended and the Earth may be headed into a cooling trend.
It  seems increasingly likely that a warming will increase precipitation and ice  accumulation in the Polar Regions, and thus slow down or even reverse the  ongoing sea level rise.
See here update 10.
The Proudman Oceanographic Laboratory estimates the rate of  sea level rise at 1.42 plus or minus 0.14 mm/year for the period 1954 to 2003.  This is less than the estimate of 1.91 plus or minus 0.14 mm/year for the period  1902 to 1953, indicating a slowing of the rate.
See here for an analysis of sea level rise by the Proudman Oceanographic  Laboratory.  The following graph shows the rate of sea level change since  1905 using the highest quality long record tide gauges.
 
Comparison of the global mean rates of sea level change  calculated from nine long-record stations with those calculated from 177  stations averaged into 13 regions. The shaded region indicates ±1 S.E.  These records are from regions which do not experience high rates of Glacial  Isostatic Adjustment (GIA) and which are not significantly affected by  earthquakes. The comparison shows that over the common period of the two  analyses (1955-1998) there is very strong agreement between the two global  means.
Wöppelmann et al used global positioning satellite (GPS) stations to correct  tide gauge data for vertical land movements. In a 2007 paper, Wöppelmann et al  analyzed data from 160 GPS stations that were within 15 km of tide gauges to  determine the vertical movement of the tide gauges. They determined that the  global average sea-level rise from January 1999 to August 2005, after correcting  the tide gauge data by the vertical land movement, was 1.31 +/- 0.30 mm/year.  Note that this estimate is 58% less than the estimate reported (1993 - 2003) in  the IPCC AR4. See here from World Climate Report, and the study abstract here .
The movie "An Inconvenient Truth" (AIT) suggests that the Antarctic ice sheet  could melt, but in fact the temperature of Antarctica has been declining over  the last 25 years by 0.11 Celsius per decade. There has been no significant  melting during previous warm periods when temperatures were warmer than  today.
               Antarctica Temperatures 1979 - 2006 MSU Data Set (Latitude -90 to  -70)
This graph was created from the  MSU Data from www.CO2Science.org.
Antarctica ice sheet has been growing  in thickness by 5 mm/year (1992 to 2003) according to a recent mass balance  study. This net extraction of water from the global ocean, according to Wingham  et al., occurs because "mass gains from accumulating snow, particularly on the  Antarctic Peninsula and within East Antarctica, exceed the ice dynamic mass loss  from West Antarctica."
A similar story is found in  Greenland. The warmest period was not the last quarter century. Rather, as  Vinther et al. report, "the warmest year in the extended Greenland temperature  record was 1941, while the 1930s and 1940s were the warmest decades." In fact,  their newly-lengthened record reveals there has been no net warming of the  region over the last 75 years. A study of the Greenland ice sheet by Johannessen  et al. found that below 1500 meters, the mean change of ice sheet height with  time was a decline of 2.0 ± 0.9 cm/year, qualitatively in harmony with the  statements of Alley et al.; but above 1500 meters, there was a positive growth  rate of fully 6.4 ± 0.2 cm/year. Averaged over the entire ice sheet, the mean  result was also positive, at a value of 5.4 ± 0.2 cm/year, which when adjusted  for an isostatic uplift of about 0.5 cm/year yielded a mean growth rate of  approximately 5 cm/year, for a total increase in the mean thickness of the  Greenland Ice Sheet of about 55 cm over the 11-year period, which was primarily  driven by accumulation of increased snowfall over the ice sheet.
A  recent study  by Zwally et al. 2007 found the Greenland ice sheet have experienced a net  accumulation of ice which is producing a 0.03 ± 0.01 mm/year decline in  sea-level.
    Severe  Weather
The IPCC claims that global warming will result in  more severe weather. This doesn't make any sense, as most storms are caused by a  difference in temperatures of colliding air masses. If CO2 warms the Polar  Regions there will be smaller temperature differences, and less severe storms.  All other things being equal, a warmer world should have fewer, not more, severe  storms.
Unlike most storms, hurricanes are caused by difference in  temperatures between the sea surface and the storm top.
Researchers  Knutson and Tuleya examined a suite of climate models and found that they  virtually unanimously projected that in a CO2-enhanced world, the middle and  upper troposphere will warm at a faster rate than the surface, especially over  the tropical oceans. More warming aloft than at the surface makes the atmosphere  more stable and less conducive to storm formation. Thus, Knutson and Tuleya  reported that the model-projected vertical stability increases in the future  would temper (but not totally cancel out) the increase in storm intensity by  rising sea surface temperature.
However, researchers Vecchi and Soden  found that the climate models almost unanimously project that there will be an  increase in the vertical wind shear during the hurricane season which also acts  to inhibit tropical cyclone formation. The combined result is that any increase  in hurricane intensity will be so small as to be undetectable.  Incidentally, the actual vertical wind shear of Atlantic hurricanes have been  declining since 1973, the opposite of the trend predicted by the climate models.  See here .
There is absolutely no evidence of increasing severe storm events in the  real world data. Here is a graph of hurricane intensity for the USA.
For the North Atlantic as a whole, according  to the World Meteorological Organization, "Reliable data ... since the 1940s  indicate that the peak strength of the strongest hurricanes has not changed, and  the mean maximum intensity of all hurricanes has decreased."
Gulev, et al  (2000) employed NCEP/NCAR reanalysis data since 1958 to study the occurrence of  winter storms over the northern hemisphere. They found a statistically  significant (at the 95% level) decline of 1.2 cyclones per year for the period,  during which temperatures reportedly rose in much of the  hemisphere.
"Global warming causes increased storminess" makes for  interesting headlines. It also violates fundamental scientific truth and the  lessons of history.
Global hurricane activity has decreased to the lowest level in 32 years. The  Accumulated Cyclone Energy (ACE) is the combination of a storm's intensity and  longevity. See here .
The graph above shows the last 4-decades of Global and Northern Hemisphere  ACE through June 30, 2011. Global hurricane activity has continued to sink to  levels not seen since the 1970s. Note that the year indicated represents the  value of ACE through the previous 24-months for the Northern Hemisphere (bottom  line/gray boxes) and the entire global (top line/blue boxes). The area in  between represents the Southern Hemisphere total ACE.
The graph above shows the la
st 4-decades of Global Tropical Storm and Hurricane frequency —  12-month running sums through June 30, 2011. The top time series is the number  of tropical cyclones that reach at least tropical storm strength  (maximum lifetime wind speed exceeds 34-knots). The bottom time series is the  number of hurricane strength (64-knots+) tropical cyclones. The global frequency  of tropical cyclones has reached a historical low.
During the past 60 years Northern Hemisphere ACE undergoes significant  interannual variability but exhibits no significant statistical trend. The  northern hemisphere 2008 ACE was 85% of the 2005 ACE as shown in the stacked bar  chart below.
Most thunderstorms occur in the tropics, but most tornatoes occur  in the USA. Less than 1% of thunderstorms in the USA spawn tornadoes. Tornadoes  requires directional wind shear, a change of wind direction with height. Wind  shear occurs when cold and warm air masses collide. This never happens in the  tropics so tornadoes never occur there. The graph below shows that the averate  USA temperatures have increased since 1960 while the number of strong (F3 to F5)  tornadoes have declined.  See here from Dr. Roy Spencer.
An outbreak of tornadoes in 2011 in the USA was caused by  unseasonably cold spring weather. Dr. Spencer writes "An unusually warm Gulf of  Mexico of 1 or 2 degrees right now cannot explain the increase in contrast  between warm and cold air masses which is key for tornado formation because that  slight warmth cannot compete with the 10 to 20 degree below-normal air in the  Midwest and Ohio Valley which has not wanted to give way to spring yet. ...  global warming causes FEWER tornado outbreaks…not more."
Dr. Indur M. Goklany prepared a study which examines whether  losses due to such events (as measured by aggregate deaths and death rates) have  increased globally and for the United States in recent decades. It puts these  deaths and death rates into perspective by comparing them with the overall  mortality burden, and briefly discuss what trends in these measures imply about  human adaptive capacity. Globally, mortality and mortality rates have declined  by 95 percent or more since the 1920s. The largest improvements came from  declines in mortality due to droughts and floods, which apparently were  responsible for 93 percent of all deaths caused by extreme events during the  20th Century. See here .
The most telling graph is the first one in the paper below:
The chart displays data on aggregate global mortality and mortality  rates between 1900 and 2006 for the following weather-related extreme events:  droughts, extreme temperatures (both extreme heat and extreme cold),floods,  slides, waves and surges, wild fires and windstorms of different types (e.g.,  hurricanes, cyclones, tornados, typhoons, etc.). It indicates that both death  and death rates have declined at least since the 1920s. Specifically, comparing  the 1920s to the 2000–2006 period, the annual number of deaths declined from  485,200 to 22,100 (a 95 percent decline), while the death rate per million  dropped from 241.8 to 3.5 (a decline of 99 percent).
    Warming is Good  for Your Health
 The health benefits of a warmer planet  are many times greater than any harmful effect. The positive health effects of heat have been well  documented over the past quarter century.  The early studies of Bull (1973)  and Bull and Morton (1975a,b) in England and Wales, for example, demonstrated  that even normal changes in temperature are typically associated with inverse changes in death rates, especially in older people.  That  is, when temperatures rise, death rates fall, while when  temperatures fall, death rates rise.
Speculations on the  potential impact of continued warming on human health often focus on  mosquito-borne diseases. Elementary models suggest that higher global  temperatures will enhance their transmission rates and extend their geographic  ranges. However the histories of three such diseases - malaria, yellow  fever, and dengue - reveal that climate has rarely been the principal  determinant of their prevalence or range. Human activities and their impact on  local ecology have generally been much more significant. It is therefore  inappropriate to use climate-based models to predict future prevalence.
    Warming Effects on  Animals
As indicated previously, both higher temperatures  and CO2 concentrations enhance plant growth, especially for trees. This  increases the habitat available for many animals. The bulk of scientific studies  show an increase in biodiversity almost everywhere on Earth that is not  restricted by habitat destruction in response to global warming and atmospheric  CO2 enrichment.
The global warming alarmist has picked the polar bear as  its poster animal. Time magazine has told its readers that they should be  worried about polar bear extinction. The data however, does not support reasons  for concern. In the Baffin Bay region between North America and Greenland,  temperatures have been declining and the polar bear population has  declined.  In the Beauford Sea region the temperature has increased and so  has the polar bear population. In other areas the polar bear population has been  stable. So the trend of polar bear populations relative to temperature have been  opposite to what Time would lead its readers to believe.
There has been  recent warming in the western arctic as a result of the Pacific Decadal  Oscillation, which periodically shifts the climate in the western arctic by  changing ocean currents. These cycles have occurred over thousands of years. No  evidence exists that suggests that both polar bears and the conservation systems  that regulate them will not adapt and respond to the new conditions. Polar bears  have persisted through many similar climate cycles. See here for an article by Dr. Mitchell Taylor,  Polar Bear Biologist.
Kyoto Protocol - Misallocation of  Funds
Of all the major problems of the world, climate  change is one of the least important because funds spent to reduce CO2 emissions  will have an insignificant effect on climate. Computer model projections show  that full implementation of the Kyoto Protocol may result in temperature  reduction of an undetectable 0.06 Celsius by 2050 at a cost of about  $1,000,000,000,000 US. See here . (This estimate assumes  the sun has no effect on climate. Since the sun has a major effect, the 0.06  Celsius estimate is likely high by a factor of 2 or more.)
The Copenhagen Consensus (directed by  environmentalist Bjorn Lomborg) analysed the major challenges facing the world  and produced a prioritized list of opportunities responding to those challenges.  Submission by 24 United Nations ambassadors and other senior diplomats were  reviewed by economists and determined that the top priority for addressing major  world challenges would be given to communicable diseases, sanitation and water,  malnutrition, and education. Ranked toward the bottom of the 40-category list  were issues relating to climate change and the Kyoto Protocol.
An Inconvenient  Truth
Al Gore's movie "An Inconvenient Truth" (AIT) is  grossly misleading about climate change. Nearly every major statement made in  the movie is one-sided, exaggerated, or plainly false. This movie has had a  large effect on public opinion even though most scientists agree it is  misleading.
Some of the problems with AIT are:
Implies that,  during the past 650,000 years, changes in carbon dioxide levels largely caused  changes in global temperature, whereas the causality mostly runs the other way,  with CO2 changes trailing global temperature changes by hundreds to thousands of  years. Never mentions that global temperatures were warmer than the present  during each of the past four interglacial periods, even though CO2 levels were  lower.
Presents images showing what 20 feet of sea level rise would do to  the world’s major coastal communities. There is no credible evidence of an  impending collapse of the great ice sheets. We do have fairly good data on ice  mass balance changes and their effects on sea level. NASA scientist Jay Zwally  and colleagues found a combined Greenland/Antarctica ice loss sea level rise  equivalent of 0.05 mm per year during 1992-2002. At that rate, it would take a  full century to raise sea level by just 5 mm.
Presents the “hockey stick”  reconstruction of Northern Hemisphere temperature history used by the IPCC,  according to which the 1990s were likely the warmest decade of the past  millennium. It is now widely acknowledged that the hockey stick was built on a  flawed methodology and inappropriate data.
Assumes a linear relationship  between CO2 levels and global temperatures, whereas the actual CO2-warming  effect is logarithmic, meaning that the next 100 ppm increase in CO2 levels adds  only half as much heat as the previous 100 ppm increase.
Claims that the  rate of global warming is accelerating, whereas the rate has been constant for  the past 30 years to 2002—roughly 0.17°C per decade, and no warming from 2002  through 2006.
Claims that Lake Chad in Northern Africa is drying up due  to global warming. The lake is the water source for 20 million people, and it  has an average depth of only 1.5 to 4.5 meters. It has actually been dry  multiple times in the past: in 8500 BC, 5500 BC, 2000 BC and 100 BC. The lake  has shrunk in size due to a rapidly expanding population drawing water from the  lake, the introduction of irrigation technologies and local overgrazing. These  causes are neither global nor warming, and are utterly independent of CO2. In  addition, Africa as a continent experienced a dramatic shift towards dryer  weather in the end of the 19th century that is not generally attributed to  CO2.
Distracts views from the main hurricane problem facing the United  States: the ever-growing concentration of population and wealth in vulnerable  coastal regions, which is partly a consequence of federal flood insurance and  other political subsidies.
Blames global warming for the decline “since  the 1960s” of the emperor penguin population in Antarctica, implying that the  penguins are in peril, their numbers dwindling as the world warms. In fact, the  population declined in the 1970s and has been stable since the late  1980s.
Never explains why anyone should be alarmed about the current  Arctic warming, considering that our stone-age ancestors survived—and likely  benefited from—the much stronger and longer Arctic warming known as the Holocene  Climate Optimum.
Presents one climate model’s projection of increased  U.S. drought as authoritative even though another leading model forecasts  increased wetness. Climate model hydrology forecasts on regional scales are  notoriously unreliable. Most of the United States, outside the Southwest, became  wetter during 1925-2003.
Blames global warming for the record number of  typhoons hitting Japan in 2004. Local meteorological conditions, not average  global temperatures, determine the trajectory of particular storms, and data  going back to 1950 show no correlation between North Pacific storm activity and  global temperatures.
Claims that global warming endangers polar bears  even though polar bear populations are increasing in Arctic areas where it is  warming and declining in Arctic areas where it is cooling. In fact 11 of the 13  main groups in Canada are thriving, and there is evidence that the only groups  that are not thriving are in a region of the Arctic that has cooled. Polar bears  have survived the Holocene Climate Optimum and the Medieval Warm Period, both  periods were significantly warmer than today's climate.
Warns that a  doubling of pre-industrial CO2 levels to 560 ppm will so acidify sea water that  all optimal areas for coral reef construction will disappear by 2050. This is  not plausible. Coral calcification rates have increased as ocean temperatures  and CO2 levels have risen, and today’s main reef builders evolved and thrived  during the Mesozoic Period, when atmospheric CO2 levels hovered above 1,000 ppm  for 150 million years and exceeded 2,000 ppm for several
million  years.
Blames global warming for the resurgence of malaria in Kenya, even  though several studies have found no climate link and attribute the problem to  decreased spraying of homes with DDT and anti-malarial drug  resistance.
Claims that 2004 set an all-time record for the number of  tornadoes in the United States. Tornado frequency has not increased; rather, the  detection of smaller tornadoes has increased. If we consider the tornadoes that  have been detectable for many decades (category F-3 or greater), there actually  has been a downward trend since 1950.
Cites Tuvalu, Polynesia, as a place  where rising sea levels force residents to evacuate their homes. In reality, sea  levels at Tuvalu fell during the latter half of the 20th century and even during  the 1990s.
Neglects to mention that global warming could reduce the  severity of winter storms—also called frontal storms because their energy comes  from colliding air masses (fronts)—by decreasing the temperature differential  between colliding air masses.
Ignores the large role of natural  variability in Arctic climate, never mentioning either that Arctic temperatures  during the 1930s equalled or exceeded those of the late 20th century, or that  the Arctic during the early- to mid-Holocene was significantly warmer than it is  today.
Ignores a study by University of Missouri professor Curt Davis  that found an overall Antarctic ice mass gain during 1992-2003.
Neglects  to mention that NASA satellites show an Antarctic cooling trend of 0.11°C per  decade since 1978.
Calls carbon dioxide the “most important greenhouse  gas.” Water vapour and clouds are the leading contributors and account for over  70% of the greenhouse effect.
Claimed that ice cap on Mt. Kilimanjaro is  disappearing due to global warming, though satellite measurements show no  temperature change at the summit.
This is only a partial list of errors,  omissions and exaggerations.
See here from the Competitive Enterprise  Institute.
See here for  an article listing 35 errors in AIT by Christopher Monckton of  Brenchley.
The decision by the British government to distribute the film  "An Inconvenient Truth" to schools has been the subject of a legal action. The  British High Court found that the film was false or misleading in 11 respects.
In order for the film to be shown, the High Court ruled in October, 2007  that teachers must make it clear to their students that:
   1.) The  film is a political work and promotes only one side of the  argument.
   2.)  Nine inaccuracies have to be specifically  drawn to the attention of school children.
The inaccuracies are listed here .
Al Gore and the IPCC shared the 2007 Nobel Peace Price "for their efforts to  build up and disseminate greater knowledge about man-made climate change, and to  lay the foundations for the measures that are needed to counteract such change".  Irena Sendler was considered for the prize for saving 2500 children and infants  from the Nazi Warsaw Ghetto and the extermination camps during World War II. She  was not selected. See her story here .
Warnings of Global  Cooling
Nigel  Weiss, Professor Emeritus at the Department of Applied Mathematics and  Theoretical Physics at the University of Cambridge says that throughout earth's  history climate change has been driven by factors other than man: "Variable  behaviour of the sun is an obvious explanation," says Dr. Weiss, "and there is  increasing evidence that Earth's climate responds to changing patterns of solar  magnetic activity." The sun's most obvious magnetic features are sunspots,  formed as magnetic fields rip through the sun's surface. "If you look back into  the sun's past, you find that we live in a period of abnormally high solar  activity," Dr. Weiss states. These hyperactive periods do not last long,  "perhaps 50 to 100 years, then you get a crash," says Dr. Weiss. 'It's a  boom-bust system, and I would expect a crash soon."
 
In addition to  the 11-year cycle, sunspots almost entirely "crash," or die out, every 200 years  or so as solar activity diminishes. When the crash occurs, the Earth can cool  dramatically. These phenomenon, known as "Grand minima," have recurred over the  past 10,000 years, if not longer. In the 17th century, sunspots almost  completely disappeared for 70 years. That was the coldest interval of the Little  Ice Age, when New York Harbour froze, allowing walkers to journey from Manhattan  to Staten Island, and when Viking colonies abandoned Greenland, a once verdant  land that became tundra.
 
In contrast, when the sun is very active,  such as the period we're now in, the Earth can warm dramatically. This was the  case during the Medieval Warm Period, when the Vikings first colonized Greenland  and when Britain was wine-growing country.
 
No one knows precisely  when a crash will occur but some expect it soon, because the sun's polar field  is now at its weakest since measurements began in the early 1950s. Some predict  the crash within five years, and many speculate about its effect on global  warming. Several authorities are now warning of global cooling because the sun  has entered a quiet period.
A Russian Academy of Sciences report in  August 2006 warns that global cooling could develop on Earth in 50 years and  have serious consequences.
David Archibal presentation titled " The Past  and Future of Climate" here presented to the Lavoisier Group's 2007  Workshop in Melbourne, Australia, shows a forecast of global temperatures  based on a detailed analysis of sunspot cycles. He expects the next sunspot  cycle (24) to be weak resulting in the start of a long cooling trend. The  forecast shows a 1.5 oC drop in global temperature from 2007 to 2025.  He warns "...this will have a large and negative effect on Canadian grain  production...".
On July 1, 2008, the Space  and Science Research Center , a solar research organization, issued a formal  declaration on climate change: Global warming has ended -  a new climate  era of pronounced cold weather has begun.
