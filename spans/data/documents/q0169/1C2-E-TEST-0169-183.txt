Approximating the Bandwidth Via Volume Respecting Embeddings
by            Uriel Feige , 1999
"... A linear arrangement of an n-vertex graph is a one-to-one mapping of its vertices  to the integers f1; : : : ; ng. The bandwidth of a linear arrangement is the maximum  difference between mapped values of adjacent vertices. The problem of finding a linear  arrangement with smallest possible bandwidt ..."
Abstract - Cited by 81 (3 self) - Add to MetaCart
A linear arrangement of an n-vertex graph is a one-to-one mapping of its vertices  to the integers f1; : : : ; ng. The bandwidth of a linear arrangement is the maximum  difference between mapped values of adjacent vertices. The problem of finding a linear  arrangement with smallest possible bandwidth in NP-hard. We present a randomized  algorithm that runs in nearly linear time and outputs a linear arrangement whose  bandwidth is within a polylogarithmic multiplicative factor of optimal. Our algorithm is  based on a new notion, called volume respecting embeddings, which is a natural extension  of small distortion embeddings of Bourgain and of Linial, London and Rabinovich.  1 Introduction  We consider the problem of minimizing the bandwidth of an undirected connected graph G(V; E), where n = jV j and m = jEj. One needs to find a linear arrangement of the vertices, namely, a one-to-one mapping f : V \Gamma! f1; 2; : : : ng, for which the bandwidth, i.e. max (i;j)2E jf(i) \Gamma f(j)j, i...
A Combined Unifrontal/Multifrontal Method for Unsymmetric Sparse Matrices
by            Timothy A. Davis, Iain S. Duff - ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE , 1995
"... We discuss the organization of frontal matrices in multifrontal methods for the solution of  large sparse sets of unsymmetric linear equations. In the multifrontal method, work on a frontal  matrix can be suspended, the frontal matrix can be stored for later reuse, and a new frontal  matrix can be g ..."
Abstract - Cited by 52 (10 self) - Add to MetaCart
We discuss the organization of frontal matrices in multifrontal methods for the solution of  large sparse sets of unsymmetric linear equations. In the multifrontal method, work on a frontal  matrix can be suspended, the frontal matrix can be stored for later reuse, and a new frontal  matrix can be generated. There are thus several frontal matrices stored during the factorization  and one or more or these are assembled (summed) when creating a new frontal matrix. Although  this means that arbitrary sparsity patterns can be handled efficiently, extra work is required to  sum the frontal matrices together and can be costly because indirect addressing is required. The  (uni-)frontal method avoids this extra work by factorizing the matrix with a single frontal matrix.  Rows and columns are added to the frontal matrix, and pivot rows and columns are removed.  Data movement is simpler, but higher fill-in can result if the matrix cannot be permuted into a  variable-band form with small profile...
Aspects of Unstructured Grids and Finite-Volume Solvers for the Euler and Navier-Stokes Equations (Part 4)
by            Timothy J. Barth , 1995
"... this report, the model was tested on various subsonic and transonic flow problems: flat plates, airfoils, wakes, etc. The model consists of a single advectiondiffusion equation with source term for a field variable which is the product of turbulence Reynolds number and kinematic viscosity,   e  RT . ..."
Abstract - Cited by 51 (0 self) - Add to MetaCart
this report, the model was tested on various subsonic and transonic flow problems: flat plates, airfoils, wakes, etc. The model consists of a single advectiondiffusion equation with source term for a field variable which is the product of turbulence Reynolds number and kinematic viscosity,   e RT . This variable is proportional to the eddy viscosity except very near a solid wall. The model equation is of the form:  D(  e  RT )  Dt  =(c ffl 2 f 2 (y  +  ) \Gamma c ffl 1 )  q  e  RT P  +( +   t  oe R  )r  2  (  e  RT ) \Gamma  1  oe ffl  (r t ) \Delta r(  e  RT ):  (6:3:3) In this equation P is the production of turbulent kinetic energy and is related to the mean flow velocity rate-of-strain and the kinematic eddy viscosity  t . Equation (6.3.3) depends on distance to solid walls in two ways. First, the damping function f 2 appearing in equation (6.3.3) depends directly on distance to the wall (in wall units). Secondly,  t depends on   e  R t and damping functions which require distance to the wall
A spectral algorithm for envelope reduction of sparse matrices
by            Stephen T. Barnard, Alex Pothen, Horst D. Simon - ACM/IEEE CONFERENCE ON SUPERCOMPUTING , 1993
"... The problem of reordering a sparse symmetric matrix to reduce its envelope size is considered. A new spectral algorithm for computing an envelope-reducing reordering is obtained by associating a Laplacian matrix with the given matrix and then sorting the components of a specified eigenvector of the  ..."
Abstract - Cited by 48 (5 self) - Add to MetaCart
The problem of reordering a sparse symmetric matrix to reduce its envelope size is considered. A new spectral algorithm for computing an envelope-reducing reordering is obtained by associating a Laplacian matrix with the given matrix and then sorting the components of a specified eigenvector of the Laplacian. This Laplacian eigenvector solves a continuous relaxation of a discrete problem related to envelope minimization called the minimum 2-sum problem. The permutation vector computed by the spectral algorithm is a closest permutation vector to the specified Laplacian eigenvector. Numerical results show that the new reordering algorithm usually computes smaller envelope sizes than those obtained from the current standards such as the Gibbs-Poole-Stockmeyer (GPS) algorithm or the reverse Cuthill-McKee (RCM) algorithm in SPARSPAK, in some cases reducing the envelope by more than a factor of two.
A Comparison of Locality Transformations for Irregular Codes
by            Hwansoo Han, Chau-wen Tseng - In Proceedings of the 5th Workshop on Languages, Compilers, and Run-time Systems for Scalable Computers , 2000
"... . Researchers have proposed several data and computation  transformations to improve locality in irregular scientific codes. We experimentally  compare their performance and present gpart, a new technique  based on hierarchical clustering. Quality partitions are constructed  quickly by clustering mu ..."
Abstract - Cited by 28 (8 self) - Add to MetaCart
. Researchers have proposed several data and computation  transformations to improve locality in irregular scientific codes. We experimentally  compare their performance and present gpart, a new technique  based on hierarchical clustering. Quality partitions are constructed  quickly by clustering multiple neighboring nodes with priority on nodes  with high degree, and repeating a few passes. Overhead is kept low by  clustering multiple nodes in each pass and considering only edges between  partitions. Experimental results show gpart matches the performance of  more sophisticated partitioning algorithms to with 6%--8%, with a small  fraction of the overhead. It is thus useful for optimizing programs whose  running times are not known.  1 Introduction  As microprocessors become increasingly fast, memory system performance begins to dictate overall performance. The ability of applications to exploit locality by keeping references in cache becomes a major factor affecting performance. Comp...
Compile-time Composition of Run-time Data and Iteration Reorderings
by            Michelle Mills Strout, Larry Carter,  Jeanne Ferrante , 2003
"... Many important applications, such as those using sparse data structures, have memory reference patterns that are unknown at compile-time. Prior work has developed runtime reorderings of data and computation that enhance locality in such applications. ..."
